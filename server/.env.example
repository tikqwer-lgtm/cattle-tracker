# Copy to .env and set ONE of the options below for the chat consultant.
#
# Option 1 — FREE, local (no payment): Ollama
# Install from https://ollama.com , then: ollama run llama3.2
# OLLAMA_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2
#
# Option 2 — Cloud (may require payment): DeepSeek
# Get key at https://platform.deepseek.com/
# DEEPSEEK_API_KEY=sk-your-key-here
